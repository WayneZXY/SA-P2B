{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[91m[WARN] Cannot find rule for <class 'pointnet2.utils.pointnet2_utils.QueryAndGroup'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.pytorch_utils.BatchNorm2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.pytorch_utils.Conv2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.pytorch_utils.SharedMLP'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'pointnet2.utils.pointnet2_modules.PointnetSAModule'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n\u001b[91m[WARN] Cannot find rule for <class 'pointnet2.models.pointnet_tracking_tiny.Pointnet_Backbone'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'pointnet2.utils.pointnet2_modules.PointnetFPModule'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.distance.CosineSimilarity'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.pytorch_utils.BatchNorm1d'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.pytorch_utils.Conv1d'>. Treat it as zero Macs and zero Params.\u001b[00m\n\u001b[91m[WARN] Cannot find rule for <class 'etw_pytorch_utils.seq.Seq'>. Treat it as zero Macs and zero Params.\u001b[00m\n[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n\u001b[91m[WARN] Cannot find rule for <class 'pointnet2.models.pointnet_tracking_tiny.Pointnet_Tracking3'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1914856000.0, 1637449.0)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from pointnet2.models import Pointnet_Tracking3\n",
    "from thop import profile \n",
    "# from torchstat import stat \n",
    "import torch \n",
    "model = Pointnet_Tracking3(input_channels=0, use_xyz=True).cuda()\n",
    "a = torch.randn((1, 256, 3)).cuda()\n",
    "b = torch.randn((1, 512, 3)).cuda()\n",
    "macs, params = profile(model, inputs=(a, b))\n",
    "macs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging # 引入logging模块\n",
    "import os\n",
    "import os.path\n",
    "import time\n",
    "# 第一步，创建一个logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO) # Log等级总开关\n",
    "# 第二步，创建一个handler，用于写入日志文件\n",
    "rq = time.strftime('%Y%m%d%H%M', time.localtime(time.time()))\n",
    "# log_path = os.path.dirname(os.getcwd()) + '/Logs/'\n",
    "log_path = os.getcwd() + '/Logs/'\n",
    "# print(log_path)\n",
    "log_name = log_path + rq + '.log'\n",
    "logfile = log_name\n",
    "# os.makedirs(log_path)\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(logging.DEBUG) # 输出到file的log等级的开关\n",
    "# 第三步，定义handler的输出格式\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "fh.setFormatter(formatter)\n",
    "# 第四步，将logger添加到handler里面\n",
    "logger.addHandler(fh)\n",
    "# 日志\n",
    "logger.debug('this is a logger debug message')\n",
    "logger.info('this is a logger info message')\n",
    "logger.warning('this is a logger warning message')\n",
    "logger.error('this is a logger error message')\n",
    "logger.critical('this is a logger critical message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "haha\n2\nyoyo\nlala\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class A(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(A, self).__init__()\n",
    "        self.c = c\n",
    "        print('haha')\n",
    "        print(self.c)\n",
    "    \n",
    "    def forward(self,):\n",
    "        print('lala')\n",
    "        return self.c + 1\n",
    "\n",
    "class B(A):\n",
    "\n",
    "    def __init__(self, e):\n",
    "        super(B, self).__init__(c=e)\n",
    "        self.c += 1\n",
    "        print('yoyo')\n",
    "    \n",
    "    # def forward(self):\n",
    "    #     print('yoyo2')\n",
    "\n",
    "class C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C, self).__init__()\n",
    "        self.backbone = A()\n",
    "        print('sasa')\n",
    "\n",
    "    def forward(self):\n",
    "        print('gaga')\n",
    "        return self.backbone(1)\n",
    "\n",
    "b = B(2)\n",
    "b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): PointnetFPModule(\n",
       "    (mlp): SharedMLP(\n",
       "      (layer0): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normlayer): BatchNorm2d(\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PointnetFPModule(\n",
       "    (mlp): SharedMLP(\n",
       "      (layer0): Conv2d(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normlayer): BatchNorm2d(\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): PointnetFPModule(\n",
       "    (mlp): SharedMLP(\n",
       "      (layer0): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normlayer): BatchNorm2d(\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import etw_pytorch_utils as pt_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pointnet2.utils.pointnet2_modules import PointnetSAModule, PointnetFPModule\n",
    "# A = (\n",
    "#                 pt_utils.Seq(256)\n",
    "#                 .conv1d(1, bn=True, activation=None))\n",
    "A = nn.ModuleList()\n",
    "A.append(PointnetFPModule(\n",
    "                mlp=[512, 256] \n",
    "            ))\n",
    "A.append(PointnetFPModule(\n",
    "                mlp=[384, 256] \n",
    "            ))\n",
    "A.append(PointnetFPModule(\n",
    "                mlp=[256, 256] \n",
    "            ))\n",
    "A\n",
    "# A = nn.Linear(256, 3)\n",
    "# a = torch.ones((3, 256, 1024))\n",
    "# # b = A(a).squeeze(1)\n",
    "# b = b.sigmoid()\n",
    "# b.shape\n",
    "# unxyz = torch.rand((8, 1024, 3), dtype=torch.float32).cuda()\n",
    "# xyz1 = torch.rand((1, 2, 3), dtype=torch.float32).cuda()\n",
    "# xyz2 = torch.rand((8, 256, 3), dtype=torch.float32).cuda()\n",
    "# xyz3 = torch.rand((8, 512, 3), dtype=torch.float32).cuda()\n",
    "# feats1 = torch.rand((8, 256, 128), dtype=torch.float32).cuda()\n",
    "# feats2 = torch.rand((8, 256, 256), dtype=torch.float32).cuda()\n",
    "# feats3 = torch.rand((8, 128, 512), dtype=torch.float32).cuda()\n",
    "# aux_module = PointnetFPModule2()\n",
    "# inter_feats1 = aux_module(unxyz, xyz3, feats3)\n",
    "# inter_feats1.shape\n",
    "# xyz = [0.33 * xyz1+0.33 * xyz1+0.33 * xyz1]\n",
    "# xyz[0], xyz1\n",
    "# xyzt = torch.cat(xyz, dim=1)\n",
    "# xyzt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "from cupy.core.dlpack import toDlpack\n",
    "from cupy.core.dlpack import fromDlpack\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "import torch\n",
    "from visualize import Visualizer\n",
    "vis = Visualizer('SA-P2B', port = 8097)\n",
    "\n",
    "#pytorch->cupy\n",
    "for i in range(10):\n",
    "    xyz1 = torch.rand((1), dtype=torch.float32).cuda()\n",
    "    cupy_data = fromDlpack(to_dlpack(xyz1))\n",
    "    # type(cupy_data)\n",
    "    vis.plot('sds', cupy_data.item())\n",
    "# #cupy->pytorch\n",
    "# tensor_data = from_dlpack(toDlpack(cupy_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from Dataset import SiameseTrain, SiameseTest\n",
    "# import torch\n",
    "# import numpy as np \n",
    "# from tqdm import tqdm\n",
    "# # from pointnet2.models import Pointnet_Tracking3\n",
    "# train_data = SiameseTrain(\n",
    "#         input_size=512,\n",
    "#         # path='/media/zhouxiaoyu/本地磁盘1/RUNNING/data/trianing',\n",
    "#         path='E:\\RUNNING\\data\\\\trianing',\n",
    "#         split='Valid',\n",
    "#         category_name='Car',\n",
    "#         offset_BB=0,\n",
    "#         scale_BB=1.25)\n",
    "# # test_loader = torch.utils.data.DataLoader(\n",
    "# #     dataset_Test,\n",
    "# #     # collate_fn=lambda x: x,\n",
    "# #     batch_size=8,\n",
    "# #     shuffle=True,\n",
    "# #     num_workers=0,\n",
    "# #     pin_memory=True)\n",
    "# train_dataloader = torch.utils.data.DataLoader(\n",
    "#     train_data,\n",
    "#     # collate_fn=lambda x: x,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     pin_memory=True)\n",
    "\n",
    "# # # model_num = 0\n",
    "# # # first_batch = next(iter(train_dataloader))\n",
    "# # # ratio = 0\n",
    "# for i, data in enumerate(tqdm(train_dataloader, ascii=True, position=0, desc='yada')):\n",
    "# # for i, data in enumerate([first_batch] * 5):\n",
    "#     # l = np.array(data[4][0])\n",
    "#     # idx = np.where(l == 1)[0]\n",
    "#     # if len(idx) > 50:\n",
    "#     #     data0 = data\n",
    "#     #     break\n",
    "#     if i == 800:\n",
    "#         break\n",
    "    # else:\n",
    "    # if data[3].shape[2] <  512:\n",
    "        # model_num +=1\n",
    "#     # else:\n",
    "# l = np.array(data[1][0])\n",
    "# idx = np.where(l == 1)[0]\n",
    "#     ratio += (len(l) - len(idx)) / (len(idx) + 1)\n",
    "# print(ratio / (i + 1))\n",
    "    # model_num.append(data[3].shape[2])\n",
    "# print(model_num / (i + 1))\n",
    "l = np.array(data[4][0])\n",
    "idx = np.where(l == 1)[0]\n",
    "# len(idx), len(l)\n",
    "import mayavi.mlab as mlab\n",
    "s = data[0][0] \n",
    "center = data[2][0][0, :]\n",
    "# netR = Pointnet_Tracking3(input_channels=0, use_xyz=True, test=False).cuda()\n",
    "# estimation_cla, estimation_reg, estimation_box, center_xyz, estimation_seg, estimation_offset = netR(data[3].cuda(), data[0].cuda())\n",
    "# center = center_xyz[0].detach().cpu().numpy()\n",
    "mlab.figure(bgcolor=(1, 1, 1), fgcolor=(0, 0, 0))\n",
    "mlab.points3d(s[:, 0], s[:, 1], s[:, 2], colormap='spectral', scale_factor=.06)\n",
    "# mlab.points3d(s[idx, 0], s[idx, 1], s[idx, 2], color=(1, 0, 0), colormap='spectral', scale_factor=.12)\n",
    "mlab.points3d(center[0], center[1], center[2], color=(0, 1, 0), colormap='spectral', scale_factor=.15)\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(-1.8958), tensor(-0.9693))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn((1))\n",
    "a.item() + d[0, 0], d[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "l = np.array(data[4][0])\n",
    "idx = np.where(l == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95b131478a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# m = np.load('E:\\RUNNING\\data\\\\train_data.model_PC.npy', allow_pickle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# b = np.load('E:\\RUNNING\\data\\\\train_data.list_of_BBs.npy', allow_pickle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# s.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# import open3d as o3d\n",
    "import numpy as np \n",
    "import mayavi.mlab as mlab\n",
    "# a = np.load('E:\\RUNNING\\data\\\\train_data.list_of_PCs.npy', allow_pickle=True)\n",
    "# m = np.load('E:\\RUNNING\\data\\\\train_data.model_PC.npy', allow_pickle=True)\n",
    "# b = np.load('E:\\RUNNING\\data\\\\train_data.list_of_BBs.npy', allow_pickle=True)\n",
    "s = data[0][0]\n",
    "d = data[4][0]\n",
    "# s.shape\n",
    "# len(a)\n",
    "# d = a[12].points.transpose(1, 0)\n",
    "# f = m[0].points.transpose(1, 0)\n",
    "# c = b[12].corners().transpose(1, 0)\n",
    "# c.shape\n",
    "# d.shape\n",
    "mlab.figure(bgcolor=(1, 1, 1), fgcolor=(0, 0, 0))\n",
    "# mlab.points3d(d[:, 0], d[:, 1], d[:, 2], colormap='spectral',scale_factor=.08)\n",
    "# mlab.points3d(f[:, 0], f[:, 1], f[:, 2], colormap='spectral',scale_factor=.03)\n",
    "mlab.points3d(s[:, 0], s[:, 1], s[:, 2], colormap='spectral', scale_factor=.06)\n",
    "# idx = np.array([0, 1, 2, 3, 0, 4, 5, 6, 7, 4, 5, 1, 2, 6, 7, 3])\n",
    "# mlab.plot3d(c[idx, 0],c[idx, 1], c[idx, 2], color=(1, 0, 0), colormap='spectral', representation='wireframe', line_width=8)\n",
    "mlab.points3d(s[idx, 0], s[idx, 1], s[idx, 2], color=(1, 0, 0), colormap='spectral', scale_factor=.06)\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np \n",
    "# a = np.load('E:\\RUNNING\\data\\\\train_data.list_of_BBs.npy', allow_pickle=True)\n",
    "# c = np.load('E:\\RUNNING\\data\\\\train_data.list_of_PCs.npy', allow_pickle=True)\n",
    "# # len(a)\n",
    "# d = c[12].points.transpose(1, 0)\n",
    "# b = a[12].corners().transpose(1, 0)\n",
    "# type(b)\n",
    "d = np.array(data[0][0])\n",
    "lines = [\n",
    "    [0, 4], \n",
    "    [4, 0], \n",
    "    [0, 1], \n",
    "    [1, 5], \n",
    "    [5, 1], \n",
    "    [1, 2], \n",
    "    [2, 6], \n",
    "    [6, 2], \n",
    "    [2, 3], \n",
    "    [3, 7], \n",
    "    [7, 3], \n",
    "    [3, 0], \n",
    "    [0, 4], \n",
    "    [4, 5], \n",
    "    [5, 6], \n",
    "    [6, 7], \n",
    "    [7, 4]\n",
    "]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "# line_set = o3d.geometry.LineSet(\n",
    "#     points = o3d.utility.Vector3dVector(b),\n",
    "#     lines = o3d.utility.Vector2iVector(lines)\n",
    "# )\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(d)\n",
    "\n",
    "# line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "# o3d.visualization.draw_geometries([pcd] + [line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  50999,    7650,   79140,   28119,   26209,    5043,    1918,\n",
       "          4257,    1541,   17391,   38129,   24487,    9615,   18883,\n",
       "         53089,   20284,    1509,     170,     807,     667,   16342,\n",
       "          9221,   49215,   12195,   10769,   36824,   12123,   24504,\n",
       "         11906,   14053,   13315,   13670,     273,     175,     765,\n",
       "         16015,   17043,     841,     364,     232,   18024,    8209,\n",
       "          4417,   23903,   22934,    5085,    5968,   40940,   12538,\n",
       "         44333,   32074,   15908,   55090,     168,   20254,   51253,\n",
       "         13715,   45618,    1492,     646,   13364,    1801,   12404,\n",
       "           883,    4661,   48218,   10925,   49321,   39109,   39388,\n",
       "         25178,   35596,    8269,    1743,    1783,   36264,   21418,\n",
       "         29013,   21008,   22781,   37454,   31698,   36164,   33505,\n",
       "         19055,   28979,   29624,   21787,   46634,   33693,   19030,\n",
       "         32187,   24805,   46981,   28992,   30627,    2226,   20983,\n",
       "           769,    2310,    2216,   73759,    6043,   22675,   10109,\n",
       "          1228,     560,     250,   25048,    3009,      58,      56,\n",
       "          2862,   55832,    1592,    1466,   81741,    1443,     780,\n",
       "           620,     857,    2374,    8739,   21606,     555,   16069,\n",
       "          8430,    9053,    8695,    4335,    7969,    4997,    2319,\n",
       "          3959,    4732,    5020,   24824,    3595,    2535,    1554,\n",
       "          3024,    2058,    2617,    2231,     728,    3503,       3,\n",
       "          1546,    1420,   47512,    1816,    1111,    1548,    1261,\n",
       "          1814,     596,    3360,    1454,     628,     688,     723,\n",
       "          1489,   15477,     636,     932,    2669,     971,   21534,\n",
       "         13994,    9963,    9820,    2831,   18142,    2253,   21109,\n",
       "         15461,   10497,    1475,     741,   14698,   14261,     864,\n",
       "         47713,   12306,   10190,   52425,   66699,   73926,    6342,\n",
       "         41594,   19969,   50210,   58027,   35661,   50874,   48994,\n",
       "        140522,   57412,   50688,   44995,   30214,   53291,   60798,\n",
       "         26323,   40623,   53888,   35792,   78942,   74053,   57672,\n",
       "         54764,   42123,   22419,   40462,   55600,   55683,   46318,\n",
       "         48779,   71041,   55124,   41515,   46965,   20097,   50536,\n",
       "         42787,   45193,   24813,   31944,   44662,   49479,   50906,\n",
       "         33466,   49673,   49998,   52094,   42978,   63271,   62040,\n",
       "        104906,  121201,   41489,   24782,   15361,    1389,    2322,\n",
       "         23060,    1894,    1970,    3763,    4725,    5674,    3367,\n",
       "         28928,    3429,    1859,    3099,    1175,    2035,    2221,\n",
       "           918,  100864,    2134,     567,     930,     160,   30159,\n",
       "         34998,    4907,   46094,    3137,    1212,     745,     272,\n",
       "          1308,   25001,     922,   49973,   13689,     228,   41811,\n",
       "         63474,     267,   48505,   33649,   12612,   33272,   57394,\n",
       "           270,     204,   54762,   34082,    1178,   22234,    8615,\n",
       "         70969,   45580,   75295,    1744,   29452,   32031,   37462,\n",
       "         32566,   36876,   28933,   82849,   38372,   57688,   64298,\n",
       "         49184,   50791,   58704,   42566,   49826,    3132,   10900,\n",
       "         23547,    5646,   45181,    5209,    6527,    5541,   55392,\n",
       "          7270,   42716,     387,   12458,   27127,   11067,    1851,\n",
       "          1537,    1502,    2291,    1923,    1139,     402,    1057,\n",
       "           595,     688,     870,     604,     683,     565,     679,\n",
       "           815,     669,   85486,    1547,    4655,    2844,   16004,\n",
       "          1408,    5443,    9268,   25005,    1507,     942,    1696,\n",
       "         14093,  269541,    7047,   20590,   41859,   68384,   41270,\n",
       "         11531,   16224,    1855,   10241,   20230,    5725,   11937,\n",
       "         19549,   20051,   24808,   24377,   23631,    9977,   18349,\n",
       "         30496,   22222,   28983,     952,    8388,   14606,   34568,\n",
       "         16531,     261,   22891,  242333,   22951,   47689,   29597,\n",
       "         41217,   15269,   21231,     994,   54706,   29725,    8049,\n",
       "         10919,    1912,   11105,   12266,   12206,   12485,      40,\n",
       "           238,    1844,   23725,    1739,    5289,    2207,   21124,\n",
       "          2277,    8671,    1078,     414,    7422,   44447,   71766,\n",
       "         38219,   19267,    6681,     799,    3855,    2604,      58,\n",
       "           314,    5495, 2253547,    1249,    1235,   23909,    3013,\n",
       "          9570,    4674,   10066,   12620,   27272,   21817,    6131])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import numpy as np \n",
    "b = np.load('model_pc_len.npy')\n",
    "# np.where(b == 170)[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_of_BBs = np.array(valid_data.list_of_PCs)\n",
    "np.save('valid_data.list_of_PCs.npy', list_of_BBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import numpy as np \n",
    "c = np.load('/media/zhouxiaoyu/本地磁盘/RUNNING/P2B/valid_data.list_of_PCs.npy', allow_pickle=True).tolist()\n",
    "len(c) == len(valid_data.list_of_PCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# for idx, d in enumerate(data):\n",
    "    # print(data[idx].shape)\n",
    "# from train_tracking import aux_loss\n",
    "import torch \n",
    "from mmdet.core.loss.losses import weighted_smoothl1, weighted_sigmoid_focal_loss\n",
    "label_point_set, label_cla, label_reg, object_point_set, sample_seg_label, sample_seg_offset = data\n",
    "rpn_cls_target = sample_seg_label.float()\n",
    "pos = (sample_seg_label > 0).float()\n",
    "neg = (sample_seg_label == 0).float()\n",
    "# pos.shape, neg.shape\n",
    "pos_normalizer = pos.sum()\n",
    "\n",
    "pos_normalizer = torch.clamp(pos_normalizer, min=1.0)\n",
    "# pos_normalizer\n",
    "cls_weights = pos + neg\n",
    "cls_weights = cls_weights / pos_normalizer\n",
    "# cls_weights\n",
    "reg_weights = pos\n",
    "reg_weights = reg_weights / pos_normalizer\n",
    "# rpn_cls_target.view(-1).shape\n",
    "point_cls = torch.randn((8, 1024))\n",
    "point_reg = torch.randn((8, 3, 1024))\n",
    "# aux_loss_cls = weighted_sigmoid_focal_loss(point_cls, rpn_cls_target, weight=cls_weights, avg_factor=1.)\n",
    "# aux_loss_cls\n",
    "\n",
    "# aux_loss_reg = weighted_smoothl1(point_reg.transpose(1, 2), sample_seg_offset, beta=1 / 9., weight=reg_weights[..., None], avg_factor=1.)\n",
    "# aux_loss_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 2, 2]),\n",
       " torch.Size([1, 2, 3, 2, 2, 1, 1]),\n",
       " torch.Size([2, 3, 2, 2, 1, 1, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import torch as t \n",
    "a = t.randn(2, 3, 2, 2)\n",
    "# mean = a.mean([3])\n",
    "b = a[None, ..., None, None]\n",
    "c = a[..., None, None, None]\n",
    "a.shape, b.shape, c.shape\n",
    "# a, mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel  # 多GPU情况下分布式训练\n",
    "# import torch.backends.cudnn as cudnn  # 貌似没有用到\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler  # 可用来调整学习率\n",
    "cc = torch.nn.Conv2d(10, 10, 3)\n",
    "optimizer = optim.Adam(cc.parameters(), lr=0.001, betas=(0.5, 0.999), eps=1e-06)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=12, gamma=0.2)\n",
    "scheduler.last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np \n",
    "a = np.load('E:\\RUNNING\\data\\\\train_data.model_PC.npy', allow_pickle=True)\n",
    "# len(a)\n",
    "d = a[17].points.transpose(1, 0)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(d)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "testing datas:  15%|█▌        | 47/308 [00:01<00:07, 36.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pyquaternion import Quaternion\n",
    "import torch\n",
    "\n",
    "import kitty_utils as utils\n",
    "from Dataset import SiameseTest, SiameseTrain\n",
    "from pointnet2.models import Pointnet_Tracking, Pointnet_Tracking3 \n",
    "\n",
    "def test(loader,\n",
    "        model,\n",
    "        epoch=-1,\n",
    "        shape_aggregation=\" \",\n",
    "        reference_BB=\" \",\n",
    "        max_iter=-1,\n",
    "        IoU_Space=3):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    dataset = loader.dataset\n",
    "    batch_num = 0\n",
    "\n",
    "    with tqdm(enumerate(loader), total=len(loader.dataset.list_of_anno), position=0, desc='testing datas') as t:\n",
    "        for batch in loader:          \n",
    "            batch_num = batch_num + 1\n",
    "            for PCs, BBs, _ in batch:\n",
    "                results_BBs = []  # 保存预测边界框列表\n",
    "                candidate_PCs_torchs = []\n",
    "                estimation_boxs = []\n",
    "                acboxs = []\n",
    "                gtboxs = []\n",
    "                # if batch_num == 59:\n",
    "                #     segs = []\n",
    "                #     cs = []\n",
    "                for i, _ in enumerate(PCs):\n",
    "                    # this_anno = list_of_anno[i]\n",
    "                    this_BB = BBs[i]  # 当前帧真值边界框\n",
    "                    this_PC = PCs[i]  # 当前帧点云\n",
    "                    # INITIAL FRAME\n",
    "                    if i == 0:\n",
    "                        box = BBs[i]\n",
    "                        results_BBs.append(box)\n",
    "                        model_PC = utils.getModel([this_PC], [this_BB], offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "\n",
    "                    else:\n",
    "                        previous_BB = BBs[i - 1]  # 前一帧真值边界框\n",
    "\n",
    "                        # DEFINE REFERENCE BB\n",
    "                        if (\"previous_result\".upper() in reference_BB.upper()):\n",
    "                            ref_BB = results_BBs[-1]  # 参考框选为前一帧预测边界框\n",
    "                        elif (\"previous_gt\".upper() in reference_BB.upper()):\n",
    "                            ref_BB = previous_BB  # 参考框选为前一帧真值边界框\n",
    "                            # ref_BB = utils.getOffsetBB(this_BB,np.array([-1,1,1]))\n",
    "                        elif (\"current_gt\".upper() in reference_BB.upper()):\n",
    "                            ref_BB = this_BB  # 参考框选为当前帧真值边界框\n",
    "\n",
    "                        candidate_PC, candidate_label, candidate_reg, _, _ = utils.cropAndCenterPC_label_test(\n",
    "                                        this_PC,\n",
    "                                        ref_BB,\n",
    "                                        this_BB,\n",
    "                                        offset=dataset.offset_BB,\n",
    "                                        scale=dataset.scale_BB)\n",
    "                        \n",
    "                        candidate_PCs, _, candidate_reg, candidate_seg, _ = utils.regularizePCwithlabel(\n",
    "                                        candidate_PC,\n",
    "                                        candidate_label,\n",
    "                                        candidate_reg,\n",
    "                                        dataset.input_size,\n",
    "                                        istrain=False)\n",
    "                        \n",
    "                        candidate_PCs_torch = candidate_PCs.unsqueeze(0).cuda()\n",
    "\n",
    "                        # AGGREGATION: IO vs ONLY0 vs ONLYI vs ALL\n",
    "                        if (\"firstandprevious\".upper() in shape_aggregation.upper()):\n",
    "                            model_PC = utils.getModel([PCs[0], PCs[i-1]], [results_BBs[0],results_BBs[i-1]], offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "                        elif (\"first\".upper() in shape_aggregation.upper()):\n",
    "                            model_PC = utils.getModel([PCs[0]], [results_BBs[0]], offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "                        elif (\"previous\".upper() in shape_aggregation.upper()):\n",
    "                            model_PC = utils.getModel([PCs[i-1]], [results_BBs[i-1]], offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "                        elif (\"all\".upper() in shape_aggregation.upper()):\n",
    "                            model_PC = utils.getModel(PCs[:i], results_BBs, offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "                        else:\n",
    "                            model_PC = utils.getModel(PCs[:i], results_BBs, offset=dataset.offset_BB, scale=dataset.scale_BB)\n",
    "\n",
    "                        model_PC_torch = utils.regularizePC(model_PC, dataset.input_size, istrain=False).unsqueeze(0).cuda()\n",
    "                        model_PC_torch = model_PC_torch.requires_grad_(False)\n",
    "                        candidate_PCs_torch.requires_grad_(False)\n",
    "                        candidate_PCs_torchs.append(candidate_PCs_torch)\n",
    "                        _, _, estimation_box, _,  estimation_seg = model(model_PC_torch, candidate_PCs_torch)\n",
    "                        estimation_boxs_cpu = estimation_box.squeeze(0).detach().cpu().numpy()\n",
    "                        box_idx = estimation_boxs_cpu[:, 4].argmax()  # 根据proposal-wise targetness得分确定对应的边界框索引\n",
    "                        estimation_box_cpu = estimation_boxs_cpu[box_idx, 0: 4]\n",
    "                        \n",
    "                        box = utils.getOffsetBB(ref_BB, estimation_box_cpu)\n",
    "                        rot = Quaternion(matrix=this_BB.rotation_matrix)\n",
    "                        trans = np.array(this_BB.center)\n",
    "                        gtbox = copy.deepcopy(this_BB)\n",
    "                        gtbox.translate(-trans)\n",
    "                        gtbox.rotate(rot.inverse)\n",
    "                        acbox = utils.getOffsetBB2(ref_BB, estimation_box_cpu)\n",
    "                        results_BBs.append(box)\n",
    "                        # acbox = copy.deepcopy(box)\n",
    "                        # acbox.center = estimation_box_cpu[0:3]\n",
    "                        # estimation_boxs.append(estimation_box_cpu)\n",
    "                        acboxs.append(acbox)\n",
    "                        gtboxs.append(gtbox)\n",
    "                        # if (batch_num == 59) and (i < 25):\n",
    "                        #     cs.append(candidate_seg)\n",
    "                        #     segs.append(estimation_seg)\n",
    "                    t.update(1)  # 推动进度条\n",
    "                if batch_num == 1:\n",
    "                    return candidate_PCs_torchs, gtboxs, acboxs\n",
    "                    # return candidate_PCs_torchs, segs, cs\n",
    "            # else:\n",
    "            #     t.update(1)  # 推动进度条\n",
    "            #     continue\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1, 0'\n",
    "\n",
    "# args.manualSeed = 0\n",
    "# random.seed(args.manualSeed)\n",
    "# torch.manual_seed(args.manualSeed)\n",
    "ngpu = 1\n",
    "# model = 'netR_32_Car.pth'\n",
    "# netR = Pointnet_Tracking(input_channels=0, use_xyz=True, test=True).cuda()\n",
    "netR = Pointnet_Tracking3(input_channels=0, use_xyz=True, test=True).cuda()\n",
    "if ngpu > 1:\n",
    "    netR = torch.nn.DataParallel(netR, range(ngpu))\n",
    "    # torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    # netR = torch.nn.DistributedDataParallel(netR)   \n",
    "netR.load_state_dict(torch.load('model/Cyc_model/netR_30_Cyclist.pth'))   \n",
    "# netR.cuda()\n",
    "torch.cuda.synchronize()\n",
    "# Car/Pedestrian/Van/Cyclist\n",
    "dataset_Test = SiameseTest(\n",
    "        input_size=512,\n",
    "        path='/media/zhouxiaoyu/本地磁盘/RUNNING/data/trianing',\n",
    "        split='Test',\n",
    "        category_name='Cyclist',\n",
    "        offset_BB=0,\n",
    "        scale_BB=1.25)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_Test,\n",
    "    collate_fn=lambda x: x,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "        pin_memory=True)\n",
    "\n",
    "if dataset_Test.isTiny():\n",
    "    max_epoch = 2\n",
    "else:\n",
    "    max_epoch = 1\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    candidate_PCs_torchs, gtboxs, acboxs = test(\n",
    "    # candidate_PCs_torchs, segs, cs = test(\n",
    "        test_loader,\n",
    "        netR,\n",
    "        epoch=epoch + 1,\n",
    "        shape_aggregation='firstandprevious',\n",
    "        reference_BB='previous_result',\n",
    "        # model_fusion=args.model_fusion,\n",
    "        IoU_Space=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import mayavi.mlab as mlab\n",
    "# mlab.figure(bgcolor=(1, 1, 1), fgcolor=(0, 0, 0))\n",
    "\n",
    "for i in range(12, 20):\n",
    "    s = candidate_PCs_torchs[i][0].cpu()\n",
    "    m = gtboxs[i].corners().transpose(1, 0)\n",
    "    c = acboxs[i].corners().transpose(1, 0)\n",
    "    # idxes = np.where(segs[i].sigmoid().cpu() > 0.37)[1]\n",
    "    # idxcs = np.where(cs[i].cpu()  == 1)[0]\n",
    "    # print(len(idxes), len(idxcs))\n",
    "    mlab.figure(bgcolor=(1, 1, 1), fgcolor=(0, 0, 0))\n",
    "#     # mlab.points3d(d[:, 0], d[:, 1], d[:, 2], colormap='spectral',scale_factor=.08)\n",
    "#     # mlab.points3d(f[:, 0], f[:, 1], f[:, 2], colormap='spectral',scale_factor=.03)\n",
    "    mlab.points3d(s[:, 0], s[:, 1], s[:, 2], colormap='spectral', scale_factor=.06)\n",
    "    # mlab.points3d(s[idxes, 0], s[idxes, 1], s[idxes, 2], color=(1, 0, 0), colormap='spectral', scale_factor=.1)\n",
    "    # mlab.points3d(s[idxcs, 0], s[idxcs, 1], s[idxcs, 2], color=(0, 0, 0.8), colormap='spectral', scale_factor=.09) \n",
    "    idx = np.array([0, 1, 2, 3, 0, 4, 5, 6, 7, 4, 5, 1, 2, 6, 7, 3])\n",
    "    mlab.plot3d(c[idx, 0], c[idx, 1], c[idx, 2], color=(1, 0, 0), colormap='spectral', representation='wireframe', line_width=6)\n",
    "    mlab.plot3d(m[idx, 0], m[idx, 1], m[idx, 2], color=(1, 1, 0), colormap='spectral', representation='wireframe', line_width=5)\n",
    "    mlab.view(90, 70, 15)\n",
    "# # mlab.points3d(s[idx, 0], s[idx, 1], s[idx, 2], color=(1, 0, 0), colormap='spectral', scale_factor=.06)\n",
    "mlab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('zhou': conda)",
   "metadata": {
    "interpreter": {
     "hash": "004d098bffb26e03fb1d4c8c8d18b0f1b4e4c0164bd957ad62c26b3d2fbe60f7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}